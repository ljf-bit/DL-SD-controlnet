import os
import cv2
import torch
import numpy as np
from tqdm import tqdm
from PIL import Image
from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation

# ================= ğŸš€ é…ç½®åŒºåŸŸ (V4.0 ç»ˆæç‰ˆ) =================

# 1. è¾“å…¥è·¯å¾„
INPUT_DIR = "/root/autodl-tmp/datasets/processed_images"

# 2. è¾“å‡ºè·¯å¾„ (å»ºè®®æ–°å»ºæ–‡ä»¶å¤¹)
OUTPUT_DIR = "./autodl-tmp/datasets/semantic_maps_final_v4"

# 3. æ¨¡å‹è·¯å¾„
# å¦‚æœä½ å·²ç»ä¸‹è½½åˆ°æœ¬åœ°ï¼Œä¿æŒè¿™ä¸ªè·¯å¾„ï¼›
# å¦‚æœæŠ¥é”™æ‰¾ä¸åˆ°ï¼Œå¯ä»¥æ”¹å› "nvidia/segformer-b5-finetuned-ade20k-512-512" è®©å®ƒåœ¨çº¿ä¸‹è½½
MODEL_REPO = "/root/autodl-tmp/segformer_b5_weights" 
# å¤‡ç”¨åœ¨çº¿åœ°å€ (å¦‚æœæœ¬åœ°åŠ è½½å¤±è´¥ï¼Œå–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œ)
# MODEL_REPO = "nvidia/segformer-b5-finetuned-ade20k-512-512"

# 4. é¢œè‰²å®šä¹‰ (BGRæ ¼å¼ - OpenCVé»˜è®¤)
PALETTE = {
    "background": (0, 0, 0),       # é»‘è‰² - èƒŒæ™¯/å¤©ç©º
    "building":   (0, 0, 128),     # æš—çº¢ - å»ºç­‘ä¸»ä½“/å¢™/æœ¨æ„/å¤©èŠ±æ¿
    "ground":     (128, 128, 128), # ç°è‰² - åœ°é¢/è·¯
    "tree":       (34, 139, 34),   # æ£®æ—ç»¿ - æ ‘æœ¨/æ¤ç‰©
    "stairs":     (0, 255, 255),   # é»„è‰² - å°é˜¶/æ¥¼æ¢¯ (ä¿®å¤é‡ç‚¹)
    "door_win":   (255, 0, 0)      # äº®è“ - é—¨çª— (ç»†èŠ‚å¢å¼º)
}

# 5. è¾¹ç¼˜çº¿æ¡é¢œè‰² (ç™½è‰²)
EDGE_COLOR = (255, 255, 255)

# ==========================================================

def main():
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print(f"ğŸš€ æ­£åœ¨åˆå§‹åŒ– SegFormer B5 (é«˜ç²¾åº¦æ¨¡å¼)...")
    print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {MODEL_REPO}")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        # åŠ è½½æ¨¡å‹
        processor = SegformerImageProcessor.from_pretrained(MODEL_REPO)
        model = SegformerForSemanticSegmentation.from_pretrained(MODEL_REPO).to(device)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ å»ºè®®: æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°† MODEL_REPO æ”¹ä¸º 'nvidia/segformer-b5-finetuned-ade20k-512-512'")
        return

    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    print(f"ğŸ¯ å¼€å§‹å¤„ç† {len(files)} å¼ å›¾ç‰‡...")

    for filename in tqdm(files):
        img_path = os.path.join(INPUT_DIR, filename)
        
        try:
            # --- 1. è¯»å–å›¾ç‰‡ ---
            image_pil = Image.open(img_path).convert("RGB")
            image_cv = cv2.imread(img_path) # ç”¨äº Canny
            
            # --- 2. SegFormer æ¨ç† ---
            inputs = processor(images=image_pil, return_tensors="pt").to(device)
            with torch.no_grad():
                outputs = model(**inputs)
            
            # --- 3. ä¸Šé‡‡æ · (è¿˜åŸåˆ°åŸå›¾å°ºå¯¸) ---
            logits = torch.nn.functional.interpolate(
                outputs.logits, 
                size=image_pil.size[::-1], 
                mode="bilinear", 
                align_corners=False
            )
            # è·å–æ¯ä¸ªåƒç´ çš„ç±»åˆ« ID
            pred_seg = logits.argmax(dim=1)[0].cpu().numpy()
            
            # --- 4. ğŸ¨ æ™ºèƒ½ç±»åˆ«æ˜ å°„ (æ ¸å¿ƒé€»è¾‘) ---
            # åˆå§‹åŒ–ç”»å¸ƒ
            semantic_map = np.zeros((image_pil.height, image_pil.width, 3), dtype=np.uint8)
            
            # æˆ‘ä»¬æŒ‰ç…§ "ä»åº•åˆ°é¡¶" çš„é¡ºåºç»˜åˆ¶ï¼Œåç”»çš„è¦†ç›–å…ˆç”»çš„
            
            # A. åœ°é¢ (Ground)
            # 4=Floor, 13=Earth, 6=Road, 29=Field, 11=Sidewalk, 46=Sand, 53=Path, 95=Dirt, 14=Grass(æœ‰æ—¶ä¹Ÿç®—åœ°)
            mask_ground = np.isin(pred_seg, [4, 13, 6, 29, 11, 46, 53, 95])
            semantic_map[mask_ground] = PALETTE["ground"]
            
            # B. å»ºç­‘ä¸»ä½“ (Building) - åŒ…å«å¢™ã€æœ¨å¤´ã€å¤©èŠ±æ¿
            # 1=Building, 12=Wall, 25=House, 6=Ceiling, 91=Wood, 31=Fence, 10=Cabinet(æœ‰æ—¶è¯¯åˆ¤)
            mask_building = np.isin(pred_seg, [1, 12, 25, 6, 91, 31, 10])
            semantic_map[mask_building] = PALETTE["building"]
            
            # C. é—¨çª— (Door/Window) - è¦†ç›–åœ¨å¢™ä¸Š
            # 8=Window, 14=Door, 33=Gate
            mask_dw = np.isin(pred_seg, [8, 14, 33])
            semantic_map[mask_dw] = PALETTE["door_win"]

            # D. å°é˜¶ (Stairs) - è¦†ç›–åœ¨åœ°é¢/å»ºç­‘ä¸Š
            # 19=Stairway, 127=Step
            mask_stairs = np.isin(pred_seg, [19, 127])
            semantic_map[mask_stairs] = PALETTE["stairs"]
            
            # E. æ ‘æœ¨ (Tree) - ä¼˜å…ˆçº§æœ€é«˜ï¼Œé®æŒ¡ä¸€åˆ‡
            # 5=Tree, 17=Plant, 72=Palm, 9=Grass
            mask_tree = np.isin(pred_seg, [5, 17, 72, 9])
            semantic_map[mask_tree] = PALETTE["tree"]

            # --- 5. ğŸ–ï¸ æ³¨å…¥ Canny è¾¹ç¼˜ (çº¹ç†ç»†èŠ‚) ---
            gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
            
            # é˜ˆå€¼ (30, 150) èƒ½è¾ƒå¥½åœ°æ•æ‰ç“¦ç‰‡å’Œæœ¨çº¹
            edges = cv2.Canny(gray, 30, 150)
            
            # ç¨å¾®è†¨èƒ€ï¼Œè®©çº¿æ¡åœ¨ 512x512 ä¸‹ä¾ç„¶æ¸…æ™°
            kernel = np.ones((2,2), np.uint8)
            edges = cv2.dilate(edges, kernel, iterations=1)
            
            # åªåœ¨æœ‰è¯­ä¹‰é¢œè‰²çš„åœ°æ–¹ç”»ç™½çº¿ (å»é™¤å¤©ç©ºå™ªç‚¹)
            mask_has_color = np.any(semantic_map > 0, axis=-1)
            
            # è¿‡æ»¤è¾¹ç¼˜
            edges_filtered = np.zeros_like(edges)
            edges_filtered[mask_has_color] = edges[mask_has_color]
            
            # å åŠ ç™½è‰²çº¿æ¡
            semantic_map[edges_filtered > 0] = EDGE_COLOR

            # --- 6. ä¿å­˜ ---
            save_name = os.path.splitext(filename)[0] + "_sem.png"
            cv2.imwrite(os.path.join(OUTPUT_DIR, save_name), semantic_map)
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†å‡ºé”™ {filename}: {e}")
            import traceback
            traceback.print_exc()
            continue

    print(f"âœ… å…¨éƒ¨å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR}")
    print("ğŸ’¡ æç¤º: æ£€æŸ¥ç”Ÿæˆçš„å›¾ç‰‡ï¼Œåº”è¯¥èƒ½çœ‹åˆ°é»„è‰²çš„å°é˜¶ã€çº¢è‰²çš„å¢™å£ã€ç»¿è‰²çš„æ ‘æœ¨ä»¥åŠç™½è‰²çš„ç“¦ç‰‡çº¹ç†ã€‚")

if __name__ == "__main__":
    main()